{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stalinosmj/BeetZart/blob/main/revision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing LibrariesðŸ˜ŠðŸ˜Š"
      ],
      "metadata": {
        "id": "YhL4JoGU5jsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import converter, instrument, note, chord\n",
        "from midi2audio import FluidSynth\n",
        "import wave\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "MizSG-Pi6Bh3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to convert MIDI to Raw audio"
      ],
      "metadata": {
        "id": "4cOsuWKzaa54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MIDI files and convert to raw audio\n",
        "def load_midi_to_audio(midi_file):\n",
        "    # Create a synthesizer\n",
        "    fs = FluidSynth()\n",
        "\n",
        "    # Convert the MIDI file to an audio file\n",
        "    audio_file = 'output.wav'\n",
        "    fs.midi_to_audio(midi_file, audio_file)\n",
        "\n",
        "    # Open the audio file and read the raw audio data\n",
        "    with wave.open(audio_file, 'rb') as wave_file:\n",
        "        raw_audio_data = wave_file.readframes(wave_file.getnframes())\n",
        "\n",
        "    # Return the raw audio data\n",
        "    return raw_audio_data"
      ],
      "metadata": {
        "id": "FHo0aYlZ6CKa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to create Spectrogram"
      ],
      "metadata": {
        "id": "AEgw7x5YarGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create spectrograms using short-time Fourier transform\n",
        "def create_stft_spectrogram(audio, window_size, hop_length):\n",
        "    stft = librosa.stft(audio, window=window_size, hop_length=hop_length)\n",
        "    spectrogram = np.abs(stft)\n",
        "    return spectrogram\n"
      ],
      "metadata": {
        "id": "92vDLmlU65Eo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create spectrograms using constant-Q transform\n",
        "def create_cqt_spectrogram(audio, hop_length):\n",
        "    cqt = librosa.cqt(audio, hop_length=hop_length)\n",
        "    spectrogram = np.abs(cqt)\n",
        "    return spectrogram\n"
      ],
      "metadata": {
        "id": "t5nGSYqv65ze"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio and MIDI splitting"
      ],
      "metadata": {
        "id": "2FV2NZEgaplX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split audio and MIDI into one-second windows\n",
        "def split_into_one_second_windows(audio, midi, sample_rate):\n",
        "    num_windows = int(len(audio) / sample_rate)\n",
        "    audio_windows = []\n",
        "    midi_windows = []\n",
        "    for i in range(num_windows):\n",
        "        start = i * sample_rate\n",
        "        end = start + sample_rate\n",
        "        audio_windows.append(audio[start:end])\n",
        "        midi_windows.append(midi[start:end])\n",
        "    return audio_windows, midi_windows"
      ],
      "metadata": {
        "id": "zgz7pe0N7A4T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split audio and MIDI into eighth-second windows\n",
        "def split_into_eighth_second_windows(audio, midi, sample_rate):\n",
        "    num_windows = int(len(audio) / (sample_rate / 8))\n",
        "    audio_windows = []\n",
        "    midi_windows = []\n",
        "    for i in range(num_windows):\n",
        "        start = i * (sample_rate / 8)\n",
        "        end = start + (sample_rate / 8)\n",
        "        audio_windows.append(audio[start:end])\n",
        "        midi_windows.append(midi[start:end])\n",
        "    return audio_windows, midi_windows"
      ],
      "metadata": {
        "id": "ZlpDqyas7EBV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load trainning data"
      ],
      "metadata": {
        "id": "zPJqKUBqa14j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "midi_file = '/content/maestro-v3.0.0_2004_MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav (1).midi'\n",
        "audio = load_midi_to_audio(midi_file)\n",
        "sample_rate = 22050"
      ],
      "metadata": {
        "id": "ebjnnm807UQ_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spectogram Creation"
      ],
      "metadata": {
        "id": "Jz_olSHea6xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create spectrograms using one-second windows\n",
        "audio_windows, midi_windows = split_into_one_second_windows(audio, midi_file, sample_rate)\n",
        "spectrograms = []\n",
        "for audio_window in audio_windows:\n",
        "    stft_spectrogram = create_stft_spectrogram(audio_window, window_size=2048, hop_length=512)\n",
        "    cqt_spectrogram = create_cqt_spectrogram(audio_window, hop_length=512)\n",
        "    spectrogram = np.stack([stft_spectrogram, cqt_spectrogram], axis=-1)\n",
        "    spectrograms.append(spectrogram)"
      ],
      "metadata": {
        "id": "xwidKCtF7YF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create spectrograms using eighth-second windows\n",
        "audio_windows, midi_windows = split_into_eighth_second_windows(audio, midi_file, sample_rate)\n",
        "spectrograms = []\n",
        "for audio_window in audio_windows:\n",
        "    stft_spectrogram = create_stft_spectrogram(audio_window, window_size=2048, hop_length=512)\n",
        "    cqt_spectrogram = create_cqt_spectrogram(audio_window, hop_length=512)\n",
        "    spectrogram = np.stack([stft_spectrogram, cqt_spectrogram], axis=-1)"
      ],
      "metadata": {
        "id": "mfNVCQ-g7cLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model definition"
      ],
      "metadata": {
        "id": "4HTXkk5SbFjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CNN on spectrograms\n",
        "def train_cnn(spectrograms, labels):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=spectrograms.shape[1:]))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(spectrograms, labels, epochs=10, batch_size=32, validation_data=(val_spectrograms, val_labels))\n"
      ],
      "metadata": {
        "id": "cHQZ_GYv7goc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainning Model"
      ],
      "metadata": {
        "id": "67XJYwppbIY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CNN on one-second window spectrograms\n",
        "train_cnn(np.array(spectrograms), np.array(midi_windows))"
      ],
      "metadata": {
        "id": "qUJxlKnb7lVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train CNN on eighth-second window spectrograms\n",
        "train_cnn(np.array(spectrograms), np.array(midi_windows))"
      ],
      "metadata": {
        "id": "YBshAtNx7mgD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}